广告搜索推荐

1、分词处理

* 将爬取到的数据，使用基于TF-IDF的jieba词库对每篇文章进行分词，并写入到数据对应的类型列中

```python
for i in range(0,10879):
    # 在数据库中查询每篇文章 对每篇文章做分词处理
    contentsA = selectTypeSql(i)
    # 使用jieba分词 提取最优先的关键词 作为分类类型
    key_words = jieba.analyse.extract_tags(re, topK=1, withWeight=True,allowPOS=('ns', 'n', 'nr'), withFlag=False)
     # 判断是否具有关键词 没有则设为默认
      if len(key_words)>0:
        # 提取对应关键词的字符位
        contents = key_words[0][0]
        # 更新数据库 分类类型列
        updateType(i, contents)
    else:
        updateType(i,"默认")
        continue
```

* 对上步骤所有分词的关键词，做热词处理，选取所有关键词中前2000的关键词，做热点关键词

```python
for i in range(0,10879):
# 导出所有关键词 作为文件
with open("C:/Users/foreverqisui/Desktop/hotkey_copy1.txt", 'r', encoding='UTF-8') as file:
    re = file.read()
# 在这些关键词中 找到出现次数最多的2000个关键词
key_words = jieba.analyse.extract_tags(re, topK=2000, withWeight=True,allowPOS=('ns', 'n', 'nr'), withFlag=False)
```

* 拿到热点关键词，插入进热点表中

  ```java
      String s = "hot_key";
  		// 根据不同的划分手段 进行划分
          String[] as = s.split("a");
          for(String n:as){
              advertisingMapper.addHotKey(n);
          }
  ```

  ```java
  /**
   * 查询数据库 将类型和数据 存入redis
   */
  @Test
  void testJsonData() {
      List<String> list = advertisingMapper.getChapter();
      System.out.println(list.size());
      for (String val : list) {
          List<NewsScrapy> data = advertisingMapper.getList(val);
          for (NewsScrapy datum : data) {
       redisTemplate.opsForList().rightPush(MyRedisKey.getNewsType(val), JSON.toJSONString(datum));
          }
      }
  }
  ```

```java
// 其他类型转成JsonString类型
JSON.toJSONString(datum)
// JsonString 转成其他类型
JSONObject.parseObject(indexData)
```

